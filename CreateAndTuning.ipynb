{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CreateAndTuning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaZBiNgpr3zZ"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tempfile\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import sagemaker\n",
        "import boto3\n",
        "from sagemaker.estimator import Estimator\n",
        "\n",
        "import subprocess\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSCHkMg_r6qC"
      },
      "source": [
        "region = boto3.Session().region_name\n",
        "\n",
        "sagemaker_session = sagemaker.Session()\n",
        "smclient = boto3.client('sagemaker')\n",
        "\n",
        "bucket = sagemaker.Session().default_bucket()  # s3 bucket name, must be in the same region as the one specified above\n",
        "prefix = 'sagemaker/DEMO-hpo-keras-cifar10'\n",
        "\n",
        "role = sagemaker.get_execution_role()\n",
        "\n",
        "NUM_CLASSES = 10   # the data set has 10 categories of images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaMVjKQmr9GL"
      },
      "source": [
        "\n",
        "\n",
        "def get_image_name(ecr_repository, tensorflow_version_tag):\n",
        "    return '%s:tensorflow-%s' % (ecr_repository, tensorflow_version_tag)\n",
        "\n",
        "def build_image(name, version):\n",
        "    cmd = 'docker build -t %s --build-arg VERSION=%s -f Dockerfile .' % (name, version)\n",
        "    subprocess.check_call(shlex.split(cmd))\n",
        "\n",
        "#version tag can be found at https://hub.docker.com/r/tensorflow/tensorflow/tags/\n",
        "#e.g., latest cpu version is 'latest', while latest gpu version is 'latest-gpu'\n",
        "tensorflow_version_tag = '1.10.1'\n",
        "\n",
        "account = boto3.client('sts').get_caller_identity()['Account']\n",
        "\n",
        "domain = 'amazonaws.com'\n",
        "if (region == 'cn-north-1' or region == 'cn-northwest-1'):\n",
        "    domain = 'amazonaws.com.cn'\n",
        "\n",
        "ecr_repository=\"%s.dkr.ecr.%s.%s/test\" %(account,region,domain) # your ECR repository, which you should have been created before running the notebook\n",
        "\n",
        "image_name = get_image_name(ecr_repository, tensorflow_version_tag)\n",
        "\n",
        "print('building image:'+image_name)\n",
        "build_image(image_name, tensorflow_version_tag)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmAXQcXasJxc"
      },
      "source": [
        "hyperparameters = dict(batch_size=32, data_augmentation=True, learning_rate=.0001,\n",
        "                       width_shift_range=.1, height_shift_range=.1, epochs=1)\n",
        "hyperparameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3wcoOx-tXQv"
      },
      "source": [
        "%%time\n",
        "\n",
        "output_location = \"s3://{}/{}/output\".format(bucket,prefix)\n",
        "\n",
        "estimator = Estimator(image_name, role=role, output_path=output_location,\n",
        "                      train_instance_count=1,\n",
        "                      train_instance_type='local', hyperparameters=hyperparameters)\n",
        "estimator.fit(channels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7exHujDftcOZ"
      },
      "source": [
        "# The name of our algorithm\n",
        "algorithm_name = 'test'\n",
        "\n",
        "# If the repository doesn't exist in ECR, create it.\n",
        "exist_repo = !aws ecr describe-repositories --repository-names {algorithm_name} > /dev/null 2>&1\n",
        "\n",
        "if not exist_repo:\n",
        "    !aws ecr create-repository --repository-name {algorithm_name} > /dev/null\n",
        "\n",
        "# Get the login command from ECR and execute it directly\n",
        "!$(aws ecr get-login --region {region} --no-include-email)\n",
        "\n",
        "!docker push {image_name}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lM_qlP7mtlbq"
      },
      "source": [
        "import json\n",
        "from time import gmtime, strftime\n",
        "\n",
        "tuning_job_name = 'BYO-keras-tuningjob-' + strftime(\"%d-%H-%M-%S\", gmtime())\n",
        "\n",
        "print(tuning_job_name)\n",
        "\n",
        "tuning_job_config = {\n",
        "    \"ParameterRanges\": {\n",
        "      \"CategoricalParameterRanges\": [],\n",
        "      \"ContinuousParameterRanges\": [\n",
        "        {\n",
        "          \"MaxValue\": \"0.001\",\n",
        "          \"MinValue\": \"0.0001\",\n",
        "          \"Name\": \"learning_rate\",\n",
        "        }\n",
        "      ],\n",
        "      \"IntegerParameterRanges\": []\n",
        "    },\n",
        "    \"ResourceLimits\": {\n",
        "      \"MaxNumberOfTrainingJobs\": 9,\n",
        "      \"MaxParallelTrainingJobs\": 3\n",
        "    },\n",
        "    \"Strategy\": \"Bayesian\",\n",
        "    \"HyperParameterTuningJobObjective\": {\n",
        "      \"MetricName\": \"loss\",\n",
        "      \"Type\": \"Minimize\"\n",
        "    }\n",
        "  }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJl_LCkcttp_"
      },
      "source": [
        "training_image = image_name\n",
        "\n",
        "print('training artifacts will be uploaded to: {}'.format(output_location))\n",
        "\n",
        "training_job_definition = {\n",
        "    \"AlgorithmSpecification\": {\n",
        "      \"MetricDefinitions\": [\n",
        "        {\n",
        "          \"Name\": \"loss\",\n",
        "          \"Regex\": \"loss: ([0-9\\\\.]+)\"\n",
        "        }\n",
        "      ],\n",
        "      \"TrainingImage\": training_image,\n",
        "      \"TrainingInputMode\": \"File\"\n",
        "    },\n",
        "    \"InputDataConfig\": [\n",
        "        {\n",
        "            \"ChannelName\": \"train\",\n",
        "            \"DataSource\": {\n",
        "                \"S3DataSource\": {\n",
        "                    \"S3DataType\": \"S3Prefix\",\n",
        "                    \"S3Uri\": channels['train'],\n",
        "                    \"S3DataDistributionType\": \"FullyReplicated\"\n",
        "                }\n",
        "            },\n",
        "            \"CompressionType\": \"None\",\n",
        "            \"RecordWrapperType\": \"None\"\n",
        "        },\n",
        "        {\n",
        "            \"ChannelName\": \"test\",\n",
        "            \"DataSource\": {\n",
        "                \"S3DataSource\": {\n",
        "                    \"S3DataType\": \"S3Prefix\",\n",
        "                    \"S3Uri\": channels['test'],\n",
        "                    \"S3DataDistributionType\": \"FullyReplicated\"\n",
        "                }\n",
        "            },\n",
        "            \"CompressionType\": \"None\",\n",
        "            \"RecordWrapperType\": \"None\"\n",
        "        }\n",
        "    ],\n",
        "    \"OutputDataConfig\": {\n",
        "      \"S3OutputPath\": \"s3://{}/{}/output\".format(bucket,prefix)\n",
        "    },\n",
        "    \"ResourceConfig\": {\n",
        "      \"InstanceCount\": 1,\n",
        "      \"InstanceType\": \"ml.m4.xlarge\",\n",
        "      \"VolumeSizeInGB\": 50\n",
        "    },\n",
        "    \"RoleArn\": role,\n",
        "    \"StaticHyperParameters\": {\n",
        "        \"batch_size\":\"32\",\n",
        "        \"data_augmentation\":\"True\",\n",
        "        \"height_shift_range\":\"0.1\",\n",
        "        \"width_shift_range\":\"0.1\",\n",
        "        \"epochs\":'1'\n",
        "    },\n",
        "    \"StoppingCondition\": {\n",
        "      \"MaxRuntimeInSeconds\": 43200\n",
        "    }\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jao2aG0mt_lg"
      },
      "source": [
        "smclient.describe_hyper_parameter_tuning_job(HyperParameterTuningJobName = tuning_job_name)['HyperParameterTuningJobStatus']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crrj3QoFuAh7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}